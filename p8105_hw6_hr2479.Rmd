---
title: "p8105_hw6_hr2479"
author: "Harry Reyes"
date: "11/26/2021"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)
library(modelr)
library(purrr)
library(viridis)
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

### Problem 1

In this example, we examined potential factors associated with child birth weight. The birthweight dataset consists of roughly 4000 children. Below we load and clean the dataset prior to performing regression analyses. Data cleaning steps included converting from numeric to factor (i.e., `babysex`, `frace`, and `mrace`) and to logical (i.e., `malform`) where appropriate. We also checked for any missing data (none was found).

```{r}
birthwt = read_csv("./data/birthweight.csv") %>% 
  janitor::clean_names() %>%
  mutate(
    babysex = as.factor(babysex),
    babysex = fct_recode(babysex, 
                         "male" = "1", 
                         "female" = "2"),
    frace = as.factor(frace),
    frace = fct_recode(frace, 
                       "white" = "1", 
                       "black" = "2", 
                       "asian" = "3", 
                       "puerto rican" = "4", 
                       "other" = "8"),
    mrace = as.factor(mrace),
    mrace = fct_recode(mrace, 
                       "white" = "1", 
                       "black" = "2", 
                       "asian" = "3", 
                       "puerto rican" = "4"),
    malform = as.logical(malform)
    )

anyNA(birthwt)
```

Below is a linear regression of baby birthweight (in grams). A number of predictors were selected based on hypothesized influence on birthweight. These predictors included baby sex, head circumference at birth (in centimeters), length at birth (in centimeters), gestational age (in weeks), the presence of malformations that could affect weight (represented as a binary feature; 0 = absent, 1 = present), mother's age at delivery (in years), and mother's weight gain during pregnancy (in pounds). Sex-based differences are well described in the literature. Head size, body length, presence of malformations known to affect weight, and gestational age all seem like logical choices for factors that influence birthweight. Factors related to pregnant mothers such as mother's age at delivery and any weight gain during pregnancy also seem likely to impact child birth weight.

```{r}
proposed = lm(bwt ~ babysex + bhead + blength + gaweeks + malform + momage + wtgain, data = birthwt)

proposed %>% 
  broom::tidy()
```

Below is a plot of model residuals against fitted values. Most observations cluster in one area, suggesting the model is a fairly good fit, though a number of predictions differ greatly from the observed values.

```{r}
birthwt %>%
  add_residuals(proposed) %>%
  add_predictions(proposed) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  labs(
    title = "Plot of residuals against fitted values",
    x = "Fitted values",
    y = "Residuals"
  )
```

Here we compare our model to two others:

* One using length at birth and gestational age as predictors (main effects only)
* One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

```{r}
cv_df = 
  crossv_mc(birthwt, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
cv_df = 
  cv_df %>% 
  mutate(
    proposed = 
      map(train, ~lm(bwt ~ babysex + bhead + blength + gaweeks + malform + momage + wtgain, data = .x)),
    simple = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    complex = map(train, ~lm(bwt ~ bhead * blength * babysex, data = .x))) %>% 
  mutate(
    rmse_model_proposed = map2_dbl(proposed, test, ~rmse(model = .x, data = .y)),
    rmse_model_simple = map2_dbl(simple, test, ~rmse(model = .x, data = .y)),
    rmse_model_complex = map2_dbl(complex, test, ~rmse(model = .x, data = .y)))
```

We cross-validated prediction error and present these data as a boxplot. The model we initially proposed was the best performing model based on comparison of RMSE. The worst performing model was the simplest model that incorporated only length at birth and gestational age as predictors.

```{r}
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_boxplot()
```

### Problem 2

We used 2017 Central Park weather data to demonstrate bootstrapping using a simple linear regression with `tmax` as the response and `tmin` as the predictor. Based on 5000 bootstrap samples, we produced estimates of $\hat{r}^2$ and $\log(\hat{\beta}_0 * \hat{\beta}_1)$.

```{r}
set.seed(123)

weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

bootstrap_results = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::glance)) %>% 
  select(results) %>% 
  unnest(results)

bootstrap_results_logb = 
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(-strap, -models)%>%
  unnest(results)%>%
  select(`.id`, term, estimate) %>% 
  pivot_wider(
    names_from = "term", 
    values_from = "estimate") %>%
  rename(b0 = `(Intercept)`, b1 = tmin) %>% 
  mutate(log_b0b1 = log(b0 * b1)) 
```

Using the 5000 bootstrap estimates, we identified the 2.5% and 97.5% quantiles to provide a 95% confidence interval for $\hat{r}^2$.

```{r}
bootstrap_results %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975))%>%
  knitr::kable(digits = 3)
```

Here is a plot of the distribution of $\hat{r}^2$, which generally appears quite high. The shape of the distribution is roughly normal but not entirely symmetric.

```{r}
bootstrap_results %>% 
  ggplot(aes(x = r.squared)) + 
  geom_density() +
  labs(
    x = expression(hat(r)^2),
    y = "Density",
    title = expression(paste('Distribution of ', hat(r)^2, ' estimates'))
    ) +
    theme(plot.title = element_text(hjust = 0.5))
```

Using the 5000 bootstrap estimates, we also identified the 2.5% and 97.5% quantiles to provide a 95% confidence interval for $\log(\hat{\beta}_0 * \hat{\beta}_1)$.

```{r}
bootstrap_results_logb %>% 
  summarize(
    ci_lower = quantile(log_b0b1, 0.025), 
    ci_upper = quantile(log_b0b1, 0.975))%>%
  knitr::kable(digits = 3)
```

Here is a plot of the distribution of $\log(\hat{\beta}_0 * \hat{\beta}_1)$. As with the distribution of $\hat{r}^2$ seen above, the shape of the distribution of $\log(\hat{\beta}_0 * \hat{\beta}_1)$ is roughly normal but not entirely symmetric.

```{r}
bootstrap_results_logb%>% 
  ggplot(aes(x = log_b0b1)) + 
  geom_density() +
  labs(
    x = expression(log(hat(beta)[0] %*% hat(beta)[1])),
    y = "Density",
    title = expression(paste('Distribution of ', log(hat(beta)[0] %*% hat(beta)[1]), ' estimates'))
    ) +
    theme(plot.title = element_text(hjust = 0.5))
```